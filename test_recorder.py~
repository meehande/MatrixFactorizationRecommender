""" 
Use this to test how function scales
JSON file is updated with the key value pairs
n:time
d:time
m:time
so that most current results are always recorded. 

"""
#JSON format - to implement:
#    {n: 
#	{(m,d):
#		{n1:	[t], n2: [t],   },
#	 (m2,d2):
#		{n1:	[t], n2: [t],   }
#	}
#	
#}
#	{3:[]},
#d: {}
#
#}
#n: dict{tuple(md) : dict{n:[t]}}




import blc
import timeit
import json

n = 1000
m = 500
d = 10

filename = "test_recorder.json"

f = open(filename, 'r')
data = json.load(f)
print data
f.close()

f = open(filename, 'w+')
f.write(json.dumps(data))
f.close   
tuple_key = str((n,d))
while (m < 1000):
    
    R = blc.createR(n,m,d)
    W = blc.sampleR(R)   
    start_time = timeit.default_timer()
    (U,V) = blc.ls(R,W,d)
    run_time = timeit.default_timer()-start_time
    if(data['m'].has_key(tuple_key) and data['m'][tuple_key].has_key(str(m))):#add time - m,d,n combo already present
        data['m'][tuple_key][str(m)].append(run_time)
    elif (data['m'].has_key(tuple_key)):#add m&time - d,n already present
	data['m'][tuple_key].update({str(m):[run_time]})
    else:#add n,d,m,time
        data['m'].update({tuple_key:{str(m):[run_time]}})
    m = m + 100
#print data    
f = open(filename, 'w+')
f.write(json.dumps(data))
f.close 
    
#f.close()
    
    
    
    
    
    
